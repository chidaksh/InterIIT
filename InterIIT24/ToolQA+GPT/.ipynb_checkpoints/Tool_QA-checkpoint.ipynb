{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzl3Q6dGTjFm"
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines openai==0.28 transformers accelerate tensorflow==2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rYk1JiNLiND2"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "import jsonlines\n",
    "from typing import List, Dict, Any\n",
    "import asyncio\n",
    "import sys\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "SfDWOo7IMAK9"
   },
   "outputs": [],
   "source": [
    "key = \"\"\n",
    "fin = \"qapairs.json\"\n",
    "prompt = '''\n",
    "You are an AI assistant to answer questions. You are provided set of tools (indeed functions), description for each of the tool, arguments that each tool can take, description for each of these arguments, type of each of these arguments in the below text. Given a query, Your task involves indetifying the required set of tools to solve the query and listng them out in a json format in the order (should match with the order in which these tools should be called to solve the query) along with the list out the arguments with their values needed for each tool.\n",
    "\n",
    "Following is the tool and it's description as reference to figure out which api functions are needed to solve the query:\n",
    "{\n",
    "    \"tool_description\": \"Handle the routine tasks associated with a product's lifecycle and reduce the need for manual intervention.\",\n",
    "    \"tool_name\": \"Agent007\",\n",
    "    \"title\": \"Agent007\",\n",
    "    \"api_list\": [\n",
    "        {\n",
    "            \"name\": \"works_list\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Returns a list of work items matching the request.\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"applies_to_part\",\n",
    "                    \"argument_description\": \"Filters for work belonging to any of the provided parts\",\n",
    "                    \"argument_type\": \"array of strings\",\n",
    "                    \"argument_value_example\": \"['FEAT-123', 'ENH-123', 'PROD-123', 'CAPL-123']\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"created_by\",\n",
    "                    \"argument_description\": \"Filters for work created by any of these users\",\n",
    "                    \"argument_type\": \"array of strings\",\n",
    "                    \"argument_value_example\": \"['DEVU-123']\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"issue.priority\",\n",
    "                    \"argument_description\": \"Filters for issues with any of the provided priorities. Allowed values: p0, p1, p2, p3\",\n",
    "                    \"argument_type\": \"array of strings\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"issue.rev_orgs\",\n",
    "                    \"argument_description\": \"Filters for issues with any of the provided Rev organizations\",\n",
    "                    \"argument_type\": \"array of strings\",\n",
    "                    \"argument_value_example\": \"['REV-123']\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"limit\",\n",
    "                    \"argument_description\": \"The maximum number of works to return. The default is '50'\",\n",
    "                    \"argument_type\": \"integer (int32)\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"owned_by\",\n",
    "                    \"argument_description\": \"Filters for work owned by any of these users\",\n",
    "                    \"argument_type\": \"array of strings\",\n",
    "                    \"argument_value_example\": \"['DEVU-123']\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"stage.name\",\n",
    "                    \"argument_description\": \"Filters for records in the provided stage(s) by name\",\n",
    "                    \"argument_type\": \"array of strings\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"ticket.needs_response\",\n",
    "                    \"argument_description\": \"Filters for tickets that need a response\",\n",
    "                    \"argument_type\": \"boolean\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"ticket.rev_org\",\n",
    "                    \"argument_description\": \"Filters for tickets associated with any of the provided Rev organizations\",\n",
    "                    \"argument_type\": \"array of strings\",\n",
    "                    \"argument_value_example\": \"['REV-123']\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"ticket.severity\",\n",
    "                    \"argument_description\": \"Filters for tickets with any of the provided severities. Allowed values: blocker, high, low, medium\",\n",
    "                    \"argument_type\": \"array of strings\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"ticket.source_channel\",\n",
    "                    \"argument_description\": \"Filters for tickets with any of the provided source channels\",\n",
    "                    \"argument_type\": \"array of strings\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"type\",\n",
    "                    \"argument_description\": \"Filters for work of the provided types. Allowed values: issue, ticket, task\",\n",
    "                    \"argument_type\": \"array of strings\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"summarize_objects\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"objects\",\n",
    "                    \"argument_description\": \"List of objects to summarize\",\n",
    "                    \"argument_type\": \"array of objects\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"prioritize_objects\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Returns a list of objects sorted by priority. The logic of what constitutes priority for a given object is an internal implementation detail.\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"objects\",\n",
    "                    \"argument_description\": \"A list of objects to be prioritized\",\n",
    "                    \"argument_type\": \"array of objects\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"add_work_items_to_sprint\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Adds the given work items to the sprint\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"work_ids\",\n",
    "                    \"argument_description\": \"A list of work item IDs to be added to the sprint.\",\n",
    "                    \"argument_type\": \"array of strings\"\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"sprint_id\",\n",
    "                    \"argument_description\": \"The ID of the sprint to which the work items should be added\",\n",
    "                    \"argument_type\": \"str\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_sprint_id\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Returns the ID of the current sprint\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": []\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_similar_work_items\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Returns a list of work items that are similar to the given work item\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"work_id\",\n",
    "                    \"argument_description\": \"The ID of the work item for which you want to find similar items\",\n",
    "                    \"argument_type\": \"string\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"search_object_by_name\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"query\",\n",
    "                    \"argument_description\": \"The search string, could be for example customer’s name, part name, user name.\",\n",
    "                    \"argument_type\": \"string\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"create_actionable_tasks_from_text\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Given a text, extracts actionable insights, and creates tasks for them, which are kind of a work item.\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"argument_name\": \"text\",\n",
    "                    \"argument_description\": \"The text from which the actionable insights need to be created.\",\n",
    "                    \"argument_type\": \"string\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"who_am_i\",\n",
    "            \"url\": \"\",\n",
    "            \"description\": \"Returns the ID of the current user\",\n",
    "            \"method\": \"GET\",\n",
    "            \"required_parameters\": [],\n",
    "            \"optional_parameters\": []\n",
    "        }\n",
    "    ],\n",
    "    \"standardized_name\": \"Agent007\"\n",
    "}\n",
    "\n",
    "Here are a few examples of the output that we expect from you for the given tool (follow the same format as mentioned in the output):\n",
    "\n",
    "Input:\n",
    "        {\n",
    "            \"query\": \"Summarize issues similar to don:core:dvrv-us-1:devo/0:issue/1\",\n",
    "            \"query_id\": 1\n",
    "        }\n",
    "Output:\n",
    "        {\"answer\": [\n",
    "            {\n",
    "                \"tool_name\": \"get_similar_work_items\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"work_id\",\n",
    "                        \"argument_value\": \"don:core:dvrv-us-1:devo/0:issue/1\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"summarize_objects\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"objects\",\n",
    "                        \"argument_value\": \"$$PREV[0]\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "\n",
    "If you do not know the answer, please guess a most probable answer. Only include the answer in your response. Do not explain.\n",
    "Convert the response to a json file.\n",
    "'''\n",
    "fout = 'out.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nnayalXNUDfP"
   },
   "outputs": [],
   "source": [
    "class OpenAIgpt():\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def clean_str(self, string):\n",
    "        pattern = re.compile(r'^\\d+\\. ', flags=re.MULTILINE)\n",
    "        string = pattern.sub('', string)\n",
    "        return string.strip()\n",
    "\n",
    "    async def dispatch_openai_requests(\n",
    "        self,\n",
    "        messages_list: List[List[Dict[str, Any]]],\n",
    "        model: str,\n",
    "        temperature: float,\n",
    "        max_tokens: int,\n",
    "        top_p: float,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Dispatches requests to OpenAI API asynchronously.\n",
    "\n",
    "            Args:\n",
    "                messages_list: List of messages to be sent to OpenAI ChatCompletion API.\n",
    "                model: OpenAI model to use.\n",
    "                temperature: Temperature to use for the model.\n",
    "                max_tokens: Maximum number of tokens to generate.\n",
    "                top_p: Top p to use for the model.\n",
    "            Returns:\n",
    "                List of responses from OpenAI API.\n",
    "            \"\"\"\n",
    "        async_responses = [\n",
    "            openai.ChatCompletion.acreate(\n",
    "                model=model,\n",
    "                messages=x,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                top_p=top_p,\n",
    "            )\n",
    "            for x in messages_list\n",
    "        ]\n",
    "        return await asyncio.gather(*async_responses)\n",
    "\n",
    "    async def main(self, key, file, prompt, fout):\n",
    "      openai.api_key = key\n",
    "      file_path = file\n",
    "      with open(file_path, 'r') as f:\n",
    "          contents = json.load(f)\n",
    "\n",
    "      query_messages = []\n",
    "      attributes = []\n",
    "      for item in contents:\n",
    "          message = item[\"question\"]\n",
    "          query_messages.append([\n",
    "              {\"role\": \"system\", \"content\": prompt},\n",
    "              {\"role\": \"user\", \"content\": message}\n",
    "          ])\n",
    "      generated_text = []\n",
    "      for i in tqdm.trange(0, len(query_messages), 5):\n",
    "          try:\n",
    "              response = await self.dispatch_openai_requests(\n",
    "                      messages_list=query_messages[i:i+5],\n",
    "                      model=\"gpt-3.5-turbo\",\n",
    "                      temperature=1.0,\n",
    "                      max_tokens=2048,\n",
    "                      top_p=1.0,\n",
    "                  )\n",
    "          except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "          for j in range(len(response)):\n",
    "              generated_text.append({response[j]\n",
    "                                    [\"choices\"][0][\"message\"][\"content\"]})\n",
    "      return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUX6qQcrM30w",
    "outputId": "65748ade-cc92-4c2d-a22a-be9e54c678cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:47<00:00, 23.93s/it]\n"
     ]
    }
   ],
   "source": [
    "ob = OpenAIgpt()\n",
    "ans = asyncio.run(ob.main(key,fin,prompt,fout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yZYgm9txrMNk"
   },
   "outputs": [],
   "source": [
    "output_file_path = fout\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "  json.dump(ans, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTgAJLok4rvk"
   },
   "outputs": [],
   "source": [
    "class Llama_7b():\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def clean_str(self, string):\n",
    "        pattern = re.compile(r'^\\d+\\. ', flags=re.MULTILINE)\n",
    "        string = pattern.sub('', string)\n",
    "        return string.strip()\n",
    "\n",
    "    def infer(self, file, prompt):\n",
    "        model = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "        # tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        generator = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            token=\"\"\n",
    "        )\n",
    "        file_path = file\n",
    "        with open(file_path, 'r') as f:\n",
    "            contents = json.load(f)\n",
    "\n",
    "        query_messages = []\n",
    "        attributes = []\n",
    "        response = []\n",
    "\n",
    "        for item in contents:\n",
    "            message = item[\"question\"]\n",
    "            message = prompt + message + '\\nAnswer:'\n",
    "            msg_list = generator(\n",
    "                message,\n",
    "                # do_sample=True,\n",
    "                # top_k=10,\n",
    "                num_return_sequences=1,\n",
    "                max_length=500,\n",
    "            )\n",
    "            response.append(msg_list[0][\"generated_text\"])\n",
    "        return response\n",
    "\n",
    "    def main(self, file, prompt, fout):\n",
    "        response = self.infer(file, prompt)\n",
    "        generated_text = []\n",
    "        for j in range(len(response)):\n",
    "            generated_text.append({\"model_answer\": response[j]})\n",
    "\n",
    "        print(generated_text[0], len(generated_text))\n",
    "        output_file_path = fout\n",
    "        with jsonlines.open(output_file_path, 'w') as writer:\n",
    "            for row in generated_text:\n",
    "                writer.write(row)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
